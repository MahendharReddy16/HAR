{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.compat.v1.Session(graph= tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x000001FA6354C630>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 761, in __del__\n",
      "    if self._session is not None:\n",
      "AttributeError: 'Session' object has no attribute '_session'\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 1.2773 - accuracy: 0.4693 - val_loss: 1.0427 - val_accuracy: 0.5741\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.9190 - accuracy: 0.6035 - val_loss: 0.9349 - val_accuracy: 0.5677\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.7878 - accuracy: 0.6390 - val_loss: 0.7974 - val_accuracy: 0.6098\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.7117 - accuracy: 0.6517 - val_loss: 0.7804 - val_accuracy: 0.6132\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.6653 - accuracy: 0.6598 - val_loss: 0.7542 - val_accuracy: 0.6230\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.6326 - accuracy: 0.6632 - val_loss: 0.7230 - val_accuracy: 0.6183\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.5961 - accuracy: 0.6810 - val_loss: 0.9588 - val_accuracy: 0.5918\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.5895 - accuracy: 0.6968 - val_loss: 0.7776 - val_accuracy: 0.6322\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.5400 - accuracy: 0.7269 - val_loss: 0.6660 - val_accuracy: 0.7394\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.5245 - accuracy: 0.7576 - val_loss: 0.6615 - val_accuracy: 0.7384\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.4953 - accuracy: 0.7801 - val_loss: 0.5606 - val_accuracy: 0.7621\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.5806 - accuracy: 0.7232 - val_loss: 0.6552 - val_accuracy: 0.7201\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.4487 - accuracy: 0.7843 - val_loss: 0.5487 - val_accuracy: 0.7594\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.4046 - accuracy: 0.8067 - val_loss: 0.5499 - val_accuracy: 0.7774\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.4314 - accuracy: 0.7935 - val_loss: 0.6065 - val_accuracy: 0.7516\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.4058 - accuracy: 0.8036 - val_loss: 0.5485 - val_accuracy: 0.7638\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.4001 - accuracy: 0.8028 - val_loss: 0.5619 - val_accuracy: 0.7655\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.3802 - accuracy: 0.8165 - val_loss: 0.5104 - val_accuracy: 0.7828\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.3702 - accuracy: 0.8210 - val_loss: 0.5687 - val_accuracy: 0.7781\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.3626 - accuracy: 0.8327 - val_loss: 0.5845 - val_accuracy: 0.7995\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.3460 - accuracy: 0.8471 - val_loss: 0.4911 - val_accuracy: 0.8283\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.3216 - accuracy: 0.8908 - val_loss: 0.4370 - val_accuracy: 0.8724\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2585 - accuracy: 0.9210 - val_loss: 0.5111 - val_accuracy: 0.8782\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2526 - accuracy: 0.9297 - val_loss: 0.4791 - val_accuracy: 0.8914\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2659 - accuracy: 0.9234 - val_loss: 0.4733 - val_accuracy: 0.8806\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2114 - accuracy: 0.9397 - val_loss: 0.6636 - val_accuracy: 0.8812\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1921 - accuracy: 0.9419 - val_loss: 0.5583 - val_accuracy: 0.8860\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2001 - accuracy: 0.9416 - val_loss: 0.4912 - val_accuracy: 0.8979\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1836 - accuracy: 0.9406 - val_loss: 0.5204 - val_accuracy: 0.9030\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1906 - accuracy: 0.9416 - val_loss: 0.4287 - val_accuracy: 0.9063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fa0dccefd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        10        0                   0   \n",
      "SITTING                  3      378       110        0                   0   \n",
      "STANDING                 0       69       462        1                   0   \n",
      "WALKING                  0        0         2      456                  25   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 416   \n",
      "WALKING_UPSTAIRS         0        0         2        1                  19   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            17  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                           13  \n",
      "WALKING_DOWNSTAIRS                 4  \n",
      "WALKING_UPSTAIRS                 449  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4293035353590176, 0.9063454270362854]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(32, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 1.3283 - accuracy: 0.4455 - val_loss: 1.2288 - val_accuracy: 0.4455\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 1.1613 - accuracy: 0.4951 - val_loss: 1.0449 - val_accuracy: 0.5718\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 1.0198 - accuracy: 0.5180 - val_loss: 1.1316 - val_accuracy: 0.5765\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.8286 - accuracy: 0.6193 - val_loss: 0.7495 - val_accuracy: 0.6278\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.7025 - accuracy: 0.6598 - val_loss: 0.7118 - val_accuracy: 0.6322\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.6752 - accuracy: 0.6609 - val_loss: 0.7598 - val_accuracy: 0.6328\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.6403 - accuracy: 0.6832 - val_loss: 0.7718 - val_accuracy: 0.6508\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.6045 - accuracy: 0.7225 - val_loss: 0.6928 - val_accuracy: 0.7078\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.5704 - accuracy: 0.7603 - val_loss: 0.8659 - val_accuracy: 0.6206\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.7084 - accuracy: 0.6989 - val_loss: 0.6693 - val_accuracy: 0.7370\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.4659 - accuracy: 0.8232 - val_loss: 0.6088 - val_accuracy: 0.7764\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.3616 - accuracy: 0.8857 - val_loss: 0.4857 - val_accuracy: 0.8470\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.3145 - accuracy: 0.8998 - val_loss: 0.4476 - val_accuracy: 0.8649\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2995 - accuracy: 0.9094 - val_loss: 1.9471 - val_accuracy: 0.5277\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.3885 - accuracy: 0.8649 - val_loss: 0.5509 - val_accuracy: 0.7811\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2561 - accuracy: 0.9135 - val_loss: 0.4959 - val_accuracy: 0.8636\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2663 - accuracy: 0.9132 - val_loss: 0.4422 - val_accuracy: 0.8687\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2211 - accuracy: 0.9242 - val_loss: 0.4575 - val_accuracy: 0.8653\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2396 - accuracy: 0.9236 - val_loss: 0.4649 - val_accuracy: 0.8507\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.2240 - accuracy: 0.9298 - val_loss: 0.3755 - val_accuracy: 0.8734\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1750 - accuracy: 0.9414 - val_loss: 0.4254 - val_accuracy: 0.8616\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1979 - accuracy: 0.9363 - val_loss: 0.3879 - val_accuracy: 0.8785\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1677 - accuracy: 0.9434 - val_loss: 0.4225 - val_accuracy: 0.8694\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1746 - accuracy: 0.9412 - val_loss: 0.3846 - val_accuracy: 0.8829\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1604 - accuracy: 0.9425 - val_loss: 0.3634 - val_accuracy: 0.8921\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 62s 9ms/step - loss: 0.1562 - accuracy: 0.9456 - val_loss: 0.3725 - val_accuracy: 0.8761\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1555 - accuracy: 0.9442 - val_loss: 0.3829 - val_accuracy: 0.8958\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1452 - accuracy: 0.9465 - val_loss: 0.3644 - val_accuracy: 0.8731\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1891 - accuracy: 0.9370 - val_loss: 0.3673 - val_accuracy: 0.8748\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1474 - accuracy: 0.9452 - val_loss: 0.3594 - val_accuracy: 0.8948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fbf4b4bd68>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      379        88        0                   0   \n",
      "STANDING                 0       83       445        2                   0   \n",
      "WALKING                  0        0         0      454                  37   \n",
      "WALKING_DOWNSTAIRS       0        0         0        2                 409   \n",
      "WALKING_UPSTAIRS         0        1         1       31                  25   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                           24  \n",
      "STANDING                           2  \n",
      "WALKING                            5  \n",
      "WALKING_DOWNSTAIRS                 9  \n",
      "WALKING_UPSTAIRS                 413  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3594353889522391, 0.894808292388916]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_48 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 13,894\n",
      "Trainable params: 13,894\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(32,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.75))\n",
    "model.add(LSTM(32,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.75))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='accuracy',patience=2)\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 1.4905 - accuracy: 0.3984 - val_loss: 1.3451 - val_accuracy: 0.3482\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 1.1664 - accuracy: 0.4830 - val_loss: 0.9621 - val_accuracy: 0.5755\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.9819 - accuracy: 0.5486 - val_loss: 0.8352 - val_accuracy: 0.6899\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.8936 - accuracy: 0.5711 - val_loss: 0.7979 - val_accuracy: 0.6447\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.9400 - accuracy: 0.5458 - val_loss: 0.8455 - val_accuracy: 0.5463\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.8755 - accuracy: 0.5720 - val_loss: 0.7854 - val_accuracy: 0.5840\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.8213 - accuracy: 0.5839 - val_loss: 0.7484 - val_accuracy: 0.5799\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.7985 - accuracy: 0.5903 - val_loss: 0.7399 - val_accuracy: 0.5836\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.7848 - accuracy: 0.6046 - val_loss: 0.7084 - val_accuracy: 0.6149\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.7558 - accuracy: 0.6066 - val_loss: 0.6989 - val_accuracy: 0.6152\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.7466 - accuracy: 0.6185 - val_loss: 0.6997 - val_accuracy: 0.6121\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.7356 - accuracy: 0.6277 - val_loss: 0.7710 - val_accuracy: 0.6138\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.7478 - accuracy: 0.6289 - val_loss: 1.0559 - val_accuracy: 0.4788\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.8455 - accuracy: 0.5977 - val_loss: 0.7464 - val_accuracy: 0.6183\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.7380 - accuracy: 0.6389 - val_loss: 0.7948 - val_accuracy: 0.6138\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.7080 - accuracy: 0.6425 - val_loss: 0.8116 - val_accuracy: 0.6142\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.7572 - accuracy: 0.6303 - val_loss: 0.8191 - val_accuracy: 0.6233\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 127s 17ms/step - loss: 0.7079 - accuracy: 0.6458 - val_loss: 0.7964 - val_accuracy: 0.6176\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.6961 - accuracy: 0.6465 - val_loss: 0.7906 - val_accuracy: 0.6203\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.7016 - accuracy: 0.6459 - val_loss: 0.8040 - val_accuracy: 0.6237\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.6815 - accuracy: 0.6563 - val_loss: 0.7937 - val_accuracy: 0.6162\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.6871 - accuracy: 0.6547 - val_loss: 0.7979 - val_accuracy: 0.6244\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.6910 - accuracy: 0.6557 - val_loss: 0.7772 - val_accuracy: 0.6244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc08976ef0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_52 (LSTM)               (None, 128, 20)           2400      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 128, 20)           0         \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 126       \n",
      "=================================================================\n",
      "Total params: 5,806\n",
      "Trainable params: 5,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(20,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(20,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='accuracy',patience=2)\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 1.2968 - accuracy: 0.5180 - val_loss: 0.9934 - val_accuracy: 0.6295\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.9169 - accuracy: 0.6438 - val_loss: 0.7864 - val_accuracy: 0.7282\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 121s 16ms/step - loss: 0.7902 - accuracy: 0.7095 - val_loss: 0.6773 - val_accuracy: 0.7357\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 121s 16ms/step - loss: 0.7136 - accuracy: 0.7330 - val_loss: 0.6054 - val_accuracy: 0.7849\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 123s 17ms/step - loss: 0.6720 - accuracy: 0.7591 - val_loss: 0.6572 - val_accuracy: 0.7645\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.5740 - accuracy: 0.8332 - val_loss: 0.4878 - val_accuracy: 0.8449\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.4653 - accuracy: 0.8735 - val_loss: 0.4785 - val_accuracy: 0.8558\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.3891 - accuracy: 0.8996 - val_loss: 0.4222 - val_accuracy: 0.8819\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.3449 - accuracy: 0.9100 - val_loss: 0.3793 - val_accuracy: 0.8928\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.3270 - accuracy: 0.9135 - val_loss: 0.4120 - val_accuracy: 0.8816\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.3265 - accuracy: 0.9176 - val_loss: 0.4085 - val_accuracy: 0.8989\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2833 - accuracy: 0.9227 - val_loss: 0.4937 - val_accuracy: 0.8812\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2583 - accuracy: 0.9289 - val_loss: 0.5589 - val_accuracy: 0.8734\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2394 - accuracy: 0.9325 - val_loss: 0.4196 - val_accuracy: 0.8826\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2395 - accuracy: 0.9317 - val_loss: 0.4278 - val_accuracy: 0.8870\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2187 - accuracy: 0.9339 - val_loss: 0.5180 - val_accuracy: 0.8819\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2193 - accuracy: 0.9324 - val_loss: 0.4594 - val_accuracy: 0.8873\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2146 - accuracy: 0.9397 - val_loss: 0.3987 - val_accuracy: 0.9002\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2306 - accuracy: 0.9324 - val_loss: 0.4380 - val_accuracy: 0.9030\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2062 - accuracy: 0.9366 - val_loss: 0.4683 - val_accuracy: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc1a694f28>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      407        62       22                   0   \n",
      "STANDING                 1       96       432        3                   0   \n",
      "WALKING                  0        0         1      453                  37   \n",
      "WALKING_DOWNSTAIRS       0        0         0       11                 408   \n",
      "WALKING_UPSTAIRS         0        0         0       16                  28   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                            5  \n",
      "WALKING_DOWNSTAIRS                 1  \n",
      "WALKING_UPSTAIRS                 427  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 11s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4682972089535494, 0.9039701223373413]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 128, 24)           3264      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 128, 24)           0         \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 24)                4704      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 6)                 150       \n",
      "=================================================================\n",
      "Total params: 8,118\n",
      "Trainable params: 8,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(24,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(24,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=2)\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 1.2037 - accuracy: 0.5173 - val_loss: 0.9069 - val_accuracy: 0.5718\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.8513 - accuracy: 0.6268 - val_loss: 0.7921 - val_accuracy: 0.6003\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.7388 - accuracy: 0.6911 - val_loss: 0.7528 - val_accuracy: 0.6851\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.6451 - accuracy: 0.7440 - val_loss: 0.6266 - val_accuracy: 0.7333\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.5591 - accuracy: 0.7775 - val_loss: 0.6781 - val_accuracy: 0.7214\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.4845 - accuracy: 0.8033 - val_loss: 0.5954 - val_accuracy: 0.7631\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.4270 - accuracy: 0.8478 - val_loss: 0.4335 - val_accuracy: 0.8612\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.3299 - accuracy: 0.9104 - val_loss: 0.3942 - val_accuracy: 0.8768\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.2954 - accuracy: 0.9192 - val_loss: 0.4490 - val_accuracy: 0.8734\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.2617 - accuracy: 0.9289 - val_loss: 0.3657 - val_accuracy: 0.8951\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.2330 - accuracy: 0.9344 - val_loss: 0.3991 - val_accuracy: 0.8951\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.2185 - accuracy: 0.9374 - val_loss: 0.3687 - val_accuracy: 0.8989\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 0.2235 - accuracy: 0.9343 - val_loss: 0.4335 - val_accuracy: 0.9006\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.2105 - accuracy: 0.9351 - val_loss: 0.3721 - val_accuracy: 0.8938\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 182s 25ms/step - loss: 0.2006 - accuracy: 0.9377 - val_loss: 0.3333 - val_accuracy: 0.9070\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 213s 29ms/step - loss: 0.1993 - accuracy: 0.9354 - val_loss: 0.4473 - val_accuracy: 0.8935\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 214s 29ms/step - loss: 0.1782 - accuracy: 0.9414 - val_loss: 0.3812 - val_accuracy: 0.9016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc2f095eb8>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 536        0         0        0                   0   \n",
      "SITTING                  6      353       116        2                   0   \n",
      "STANDING                 0       74       451        4                   0   \n",
      "WALKING                  0        0         0      452                  32   \n",
      "WALKING_DOWNSTAIRS       0        0         0        2                 418   \n",
      "WALKING_UPSTAIRS         0        0         0       15                   9   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             1  \n",
      "SITTING                           14  \n",
      "STANDING                           3  \n",
      "WALKING                           12  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 447  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 19s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38118069241371727, 0.9015948176383972]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_56 (LSTM)               (None, 128, 28)           4256      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128, 28)           0         \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 28)                6384      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 174       \n",
      "=================================================================\n",
      "Total params: 10,814\n",
      "Trainable params: 10,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(28,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(28,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=2)\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 214s 29ms/step - loss: 1.2012 - accuracy: 0.5029 - val_loss: 1.0125 - val_accuracy: 0.4425\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 212s 29ms/step - loss: 0.8261 - accuracy: 0.6285 - val_loss: 0.7214 - val_accuracy: 0.6216\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 209s 28ms/step - loss: 0.6916 - accuracy: 0.6912 - val_loss: 0.9501 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 214s 29ms/step - loss: 0.6101 - accuracy: 0.7364 - val_loss: 0.5421 - val_accuracy: 0.7655\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 229s 31ms/step - loss: 0.5116 - accuracy: 0.7809 - val_loss: 0.5140 - val_accuracy: 0.7635\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 258s 35ms/step - loss: 0.4753 - accuracy: 0.7968 - val_loss: 0.7294 - val_accuracy: 0.7234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc44b5bfd0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_58 (LSTM)               (None, 128, 28)           4256      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 128, 28)           0         \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 28)                6384      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 174       \n",
      "=================================================================\n",
      "Total params: 10,814\n",
      "Trainable params: 10,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(28,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.75))\n",
    "model.add(LSTM(28,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.75))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=2)\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 1.3003 - accuracy: 0.4597 - val_loss: 0.9513 - val_accuracy: 0.5375\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.9403 - accuracy: 0.5325 - val_loss: 0.8734 - val_accuracy: 0.5182\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 121s 17ms/step - loss: 0.8687 - accuracy: 0.5355 - val_loss: 0.8599 - val_accuracy: 0.5205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc5d58bf28>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_60 (LSTM)               (None, 128, 28)           4256      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128, 28)           0         \n",
      "_________________________________________________________________\n",
      "lstm_61 (LSTM)               (None, 28)                6384      \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 6)                 174       \n",
      "=================================================================\n",
      "Total params: 10,814\n",
      "Trainable params: 10,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(28,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "model.add(LSTM(28,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=2)\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 1.1266 - accuracy: 0.5020 - val_loss: 0.9131 - val_accuracy: 0.5460\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.7529 - accuracy: 0.6326 - val_loss: 0.7405 - val_accuracy: 0.6342\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.6505 - accuracy: 0.6881 - val_loss: 0.7630 - val_accuracy: 0.6658\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.5036 - accuracy: 0.7799 - val_loss: 0.5538 - val_accuracy: 0.7686\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.4192 - accuracy: 0.8275 - val_loss: 0.4469 - val_accuracy: 0.8398\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.3390 - accuracy: 0.8791 - val_loss: 0.3812 - val_accuracy: 0.8633\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 123s 17ms/step - loss: 0.2468 - accuracy: 0.9222 - val_loss: 0.4311 - val_accuracy: 0.8697\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.2197 - accuracy: 0.9268 - val_loss: 0.3363 - val_accuracy: 0.8924\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.1919 - accuracy: 0.9346 - val_loss: 0.2918 - val_accuracy: 0.9009\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.1662 - accuracy: 0.9372 - val_loss: 0.3171 - val_accuracy: 0.8992\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.1460 - accuracy: 0.9467 - val_loss: 0.3859 - val_accuracy: 0.9077\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.1543 - accuracy: 0.9465 - val_loss: 0.3544 - val_accuracy: 0.8992\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.1480 - accuracy: 0.9438 - val_loss: 0.4082 - val_accuracy: 0.9074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc77fd2fd0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  2      370        96       17                   2   \n",
      "STANDING                 0       61       468        3                   0   \n",
      "WALKING                  0        0         0      468                  26   \n",
      "WALKING_DOWNSTAIRS       0        0         0        3                 416   \n",
      "WALKING_UPSTAIRS         0        1         1        8                  46   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            4  \n",
      "STANDING                           0  \n",
      "WALKING                            2  \n",
      "WALKING_DOWNSTAIRS                 1  \n",
      "WALKING_UPSTAIRS                 415  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 12s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4081978703499752, 0.9073634147644043]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 31,558\n",
      "Trainable params: 31,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(64,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "model.add(LSTM(32,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=2)\n",
    "callbacks = [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 144s 20ms/step - loss: 1.1056 - accuracy: 0.5331 - val_loss: 0.8742 - val_accuracy: 0.6356\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.6890 - accuracy: 0.7325 - val_loss: 0.6520 - val_accuracy: 0.7615\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.4847 - accuracy: 0.8312 - val_loss: 0.4826 - val_accuracy: 0.8500\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.2758 - accuracy: 0.9173 - val_loss: 0.4425 - val_accuracy: 0.8643\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.2132 - accuracy: 0.9347 - val_loss: 0.3679 - val_accuracy: 0.8904\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.1813 - accuracy: 0.9436 - val_loss: 0.4470 - val_accuracy: 0.8860\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.1729 - accuracy: 0.9399 - val_loss: 0.4217 - val_accuracy: 0.8924\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.1462 - accuracy: 0.9452 - val_loss: 0.4563 - val_accuracy: 0.9002\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.1561 - accuracy: 0.9457 - val_loss: 0.4446 - val_accuracy: 0.8901\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.1370 - accuracy: 0.9510 - val_loss: 0.3285 - val_accuracy: 0.9128\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.1427 - accuracy: 0.9480 - val_loss: 0.5696 - val_accuracy: 0.8860\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.1353 - accuracy: 0.9518 - val_loss: 0.4174 - val_accuracy: 0.9043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x152db8f1f60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  2      375       112        0                   0   \n",
      "STANDING                 0       55       477        0                   0   \n",
      "WALKING                  0        0        15      424                  46   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 420   \n",
      "WALKING_UPSTAIRS         0        0         3       13                  23   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                           11  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 432  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 14s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41741838527891234, 0.9043094515800476]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 31,558\n",
      "Trainable params: 31,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(64,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(32,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "from keras.callbacks.callbacks import ModelCheckpoint\n",
    "checkpoint_1 = ModelCheckpoint(\"model_1.1\", monitor=\"val_accuracy\",mode=\"max\",save_best_only = True, verbose=1) \n",
    "\n",
    "\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=2)\n",
    "callbacks = [checkpoint_1,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 1.1688 - accuracy: 0.5530 - val_loss: 0.8774 - val_accuracy: 0.6518\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65185, saving model to model_1.1\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.7562 - accuracy: 0.6999 - val_loss: 0.6272 - val_accuracy: 0.7289\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65185 to 0.72888, saving model to model_1.1\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.6180 - accuracy: 0.7519 - val_loss: 0.6287 - val_accuracy: 0.7387\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72888 to 0.73872, saving model to model_1.1\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.5084 - accuracy: 0.8173 - val_loss: 0.4337 - val_accuracy: 0.8324\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.73872 to 0.83237, saving model to model_1.1\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.3413 - accuracy: 0.8984 - val_loss: 0.3665 - val_accuracy: 0.8806\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.83237 to 0.88056, saving model to model_1.1\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.2625 - accuracy: 0.9257 - val_loss: 0.3883 - val_accuracy: 0.8982\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.88056 to 0.89820, saving model to model_1.1\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.2205 - accuracy: 0.9329 - val_loss: 0.4034 - val_accuracy: 0.8938\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.89820\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 142s 19ms/step - loss: 0.2163 - accuracy: 0.9354 - val_loss: 0.3237 - val_accuracy: 0.9152\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.89820 to 0.91517, saving model to model_1.1\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.1889 - accuracy: 0.9418 - val_loss: 0.3270 - val_accuracy: 0.9114\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.91517\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.1862 - accuracy: 0.9402 - val_loss: 0.5101 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x152f0d08dd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         3        0                   0   \n",
      "SITTING                  0      375       112        0                   0   \n",
      "STANDING                 0       74       456        2                   0   \n",
      "WALKING                  0        0         0      463                   0   \n",
      "WALKING_DOWNSTAIRS       0        0         0       19                 350   \n",
      "WALKING_UPSTAIRS         0        0         0       20                   0   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            24  \n",
      "SITTING                            4  \n",
      "STANDING                           0  \n",
      "WALKING                           33  \n",
      "WALKING_DOWNSTAIRS                51  \n",
      "WALKING_UPSTAIRS                 451  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 15s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5100547778261941, 0.8839497566223145]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.75 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 31,558\n",
      "Trainable params: 31,558\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(64,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.75))\n",
    "model.add(LSTM(32,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.75))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "from keras.callbacks.callbacks import ModelCheckpoint\n",
    "checkpoint_1 = ModelCheckpoint(\"model_1.1\", monitor=\"val_accuracy\",mode=\"max\",save_best_only = True, verbose=1) \n",
    "\n",
    "\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=2)\n",
    "callbacks = [checkpoint_1,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 1.3000 - accuracy: 0.4868 - val_loss: 0.9620 - val_accuracy: 0.5911\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59111, saving model to model_1.1\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.9806 - accuracy: 0.5770 - val_loss: 0.8821 - val_accuracy: 0.5857\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.59111\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.8653 - accuracy: 0.6137 - val_loss: 0.8124 - val_accuracy: 0.6077\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.59111 to 0.60774, saving model to model_1.1\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.8039 - accuracy: 0.6249 - val_loss: 0.7777 - val_accuracy: 0.6196\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.60774 to 0.61961, saving model to model_1.1\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 142s 19ms/step - loss: 0.7677 - accuracy: 0.6489 - val_loss: 0.7959 - val_accuracy: 0.6227\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.61961 to 0.62267, saving model to model_1.1\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.7455 - accuracy: 0.6540 - val_loss: 0.8052 - val_accuracy: 0.6240\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.62267 to 0.62402, saving model to model_1.1\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.7277 - accuracy: 0.6726 - val_loss: 0.7568 - val_accuracy: 0.7268\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.62402 to 0.72684, saving model to model_1.1\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.7001 - accuracy: 0.7150 - val_loss: 0.6642 - val_accuracy: 0.7397\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.72684 to 0.73974, saving model to model_1.1\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.6514 - accuracy: 0.7252 - val_loss: 0.7880 - val_accuracy: 0.6861\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73974\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.6056 - accuracy: 0.7578 - val_loss: 0.5996 - val_accuracy: 0.8202\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.73974 to 0.82016, saving model to model_1.1\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 141s 19ms/step - loss: 0.5242 - accuracy: 0.8245 - val_loss: 0.5021 - val_accuracy: 0.8782\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.82016 to 0.87818, saving model to model_1.1\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 140s 19ms/step - loss: 0.4641 - accuracy: 0.8595 - val_loss: 1.1375 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87818\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 138s 19ms/step - loss: 0.4272 - accuracy: 0.8841 - val_loss: 0.6221 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.87818\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "LSTM=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      418        69        1                   0   \n",
      "STANDING                 0      114       406        1                   0   \n",
      "WALKING                  0        0         0      449                   2   \n",
      "WALKING_DOWNSTAIRS       0        0         0       25                 346   \n",
      "WALKING_UPSTAIRS         0        0         0       18                   3   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            3  \n",
      "STANDING                          11  \n",
      "WALKING                           45  \n",
      "WALKING_DOWNSTAIRS                49  \n",
      "WALKING_UPSTAIRS                 450  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 16s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.622152369769943, 0.8751272559165955]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 52,358\n",
      "Trainable params: 52,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(64,return_sequences = True,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(64,return_sequences = False,input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "from keras.callbacks.callbacks import ModelCheckpoint\n",
    "checkpoint_1 = ModelCheckpoint(\"model_1.1\", monitor=\"val_accuracy\",mode=\"max\",save_best_only = True, verbose=1) \n",
    "\n",
    "\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=2)\n",
    "callbacks = [checkpoint_1,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 228s 31ms/step - loss: 1.0310 - accuracy: 0.5638 - val_loss: 0.7878 - val_accuracy: 0.6614\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66135, saving model to model_1.1\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 238s 32ms/step - loss: 0.6422 - accuracy: 0.7232 - val_loss: 0.7311 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66135 to 0.71496, saving model to model_1.1\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 261s 35ms/step - loss: 0.4935 - accuracy: 0.7767 - val_loss: 0.5442 - val_accuracy: 0.7655\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.71496 to 0.76552, saving model to model_1.1\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 302s 41ms/step - loss: 0.3849 - accuracy: 0.8541 - val_loss: 0.4581 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.76552 to 0.88327, saving model to model_1.1\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 148s 20ms/step - loss: 0.2652 - accuracy: 0.9166 - val_loss: 0.3878 - val_accuracy: 0.8799\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.88327\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 130s 18ms/step - loss: 0.2290 - accuracy: 0.9282 - val_loss: 0.3590 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.88327 to 0.90261, saving model to model_1.1\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 128s 17ms/step - loss: 0.1847 - accuracy: 0.9361 - val_loss: 0.3647 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.90261\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.1663 - accuracy: 0.9426 - val_loss: 0.4156 - val_accuracy: 0.8836\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.90261\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "lstm=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 524        0         0        0                   0   \n",
      "SITTING                  2      462        23        2                   0   \n",
      "STANDING                 0      220       309        3                   0   \n",
      "WALKING                  0        0         0      441                  54   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 420   \n",
      "WALKING_UPSTAIRS         0        0         0        8                  15   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            13  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 448  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 12s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41557583960709327, 0.8836104273796082]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 71,942\n",
      "Trainable params: 71,686\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(128, input_shape=(timesteps, input_dim)))\n",
    "model.add(BatchNormalization())\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "from keras.callbacks.callbacks import ModelCheckpoint\n",
    "checkpoint_1 = ModelCheckpoint(\"best_model_1.1\", monitor=\"val_accuracy\",mode=\"max\",save_best_only = True, verbose=1) \n",
    "\n",
    "\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=3)\n",
    "callbacks = [checkpoint_1,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.8231 - accuracy: 0.6401 - val_loss: 0.7539 - val_accuracy: 0.6705\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67051, saving model to best_model_1.1\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.6254 - accuracy: 0.7359 - val_loss: 0.5794 - val_accuracy: 0.7896\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.67051 to 0.78962, saving model to best_model_1.1\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.3875 - accuracy: 0.8818 - val_loss: 0.5783 - val_accuracy: 0.8229\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78962 to 0.82287, saving model to best_model_1.1\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.2199 - accuracy: 0.9257 - val_loss: 0.3194 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.82287 to 0.90261, saving model to best_model_1.1\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1905 - accuracy: 0.9305 - val_loss: 0.2341 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.90261 to 0.90770, saving model to best_model_1.1\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.1669 - accuracy: 0.9370 - val_loss: 0.2713 - val_accuracy: 0.9118\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.90770 to 0.91177, saving model to best_model_1.1\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1669 - accuracy: 0.9376 - val_loss: 0.2513 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91177 to 0.91347, saving model to best_model_1.1\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 70s 9ms/step - loss: 0.1552 - accuracy: 0.9408 - val_loss: 0.2227 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91347 to 0.92637, saving model to best_model_1.1\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1447 - accuracy: 0.9425 - val_loss: 0.2288 - val_accuracy: 0.9277\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.92637 to 0.92772, saving model to best_model_1.1\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1417 - accuracy: 0.9389 - val_loss: 1.2786 - val_accuracy: 0.7988\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.92772\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1501 - accuracy: 0.9399 - val_loss: 0.2467 - val_accuracy: 0.9345\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.92772 to 0.93451, saving model to best_model_1.1\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1430 - accuracy: 0.9381 - val_loss: 0.2908 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.93451\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1298 - accuracy: 0.9406 - val_loss: 0.3011 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.93451\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1283 - accuracy: 0.9476 - val_loss: 0.3161 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.93451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2d9d8f00ef0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=20,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "saved_model = load_model('best_model_1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  2      405        82        0                   0   \n",
      "STANDING                 0       69       463        0                   0   \n",
      "WALKING                  0        1         2      464                  24   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 417   \n",
      "WALKING_UPSTAIRS         0        1         1        0                   1   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                            5  \n",
      "WALKING_DOWNSTAIRS                 3  \n",
      "WALKING_UPSTAIRS                 468  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, saved_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 13s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24674624278151186, 0.9345096945762634]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = saved_model.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128, 128)          70656     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 120,454\n",
      "Trainable params: 120,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model1 = Sequential()\n",
    "# Configuring the parameters\n",
    "model1.add(LSTM(128, return_sequences=True, input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "model1.add(LSTM(64))\n",
    "# Adding a dropout layer\n",
    "model1.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model1.add(Dense(n_classes, activation='sigmoid'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "from keras.callbacks.callbacks import ModelCheckpoint\n",
    "checkpoint_1 = ModelCheckpoint(\"best_model_2.1\", monitor=\"val_accuracy\",mode=\"max\",save_best_only = True, verbose=1) \n",
    "\n",
    "\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=3)\n",
    "callbacks = [checkpoint_1,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 1.0653 - accuracy: 0.5418 - val_loss: 0.8596 - val_accuracy: 0.6308\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63081, saving model to best_model_2.1\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.7825 - accuracy: 0.6428 - val_loss: 0.9171 - val_accuracy: 0.5925\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.63081\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.6863 - accuracy: 0.7084 - val_loss: 0.6890 - val_accuracy: 0.7014\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.63081 to 0.70139, saving model to best_model_2.1\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.5301 - accuracy: 0.8040 - val_loss: 0.4430 - val_accuracy: 0.8680\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.70139 to 0.86800, saving model to best_model_2.1\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.2994 - accuracy: 0.9071 - val_loss: 0.4317 - val_accuracy: 0.8738\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.86800 to 0.87377, saving model to best_model_2.1\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.2194 - accuracy: 0.9305 - val_loss: 0.3004 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.87377 to 0.89956, saving model to best_model_2.1\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1942 - accuracy: 0.9368 - val_loss: 0.3843 - val_accuracy: 0.9013\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.89956 to 0.90126, saving model to best_model_2.1\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1742 - accuracy: 0.9419 - val_loss: 0.3104 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.90126\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1577 - accuracy: 0.9436 - val_loss: 0.2489 - val_accuracy: 0.8985\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.90126\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1640 - accuracy: 0.9411 - val_loss: 0.3142 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.90126 to 0.91313, saving model to best_model_2.1\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1501 - accuracy: 0.9471 - val_loss: 0.3243 - val_accuracy: 0.9053\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91313\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1541 - accuracy: 0.9438 - val_loss: 0.3798 - val_accuracy: 0.9165\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.91313 to 0.91653, saving model to best_model_2.1\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1351 - accuracy: 0.9506 - val_loss: 0.3312 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.91653 to 0.91720, saving model to best_model_2.1\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1325 - accuracy: 0.9508 - val_loss: 0.3209 - val_accuracy: 0.9152\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91720\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1524 - accuracy: 0.9475 - val_loss: 0.3072 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91720\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1317 - accuracy: 0.9502 - val_loss: 0.2809 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.91720 to 0.91924, saving model to best_model_2.1\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1331 - accuracy: 0.9484 - val_loss: 0.2742 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.91924 to 0.92094, saving model to best_model_2.1\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1178 - accuracy: 0.9535 - val_loss: 0.3097 - val_accuracy: 0.9199\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92094\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1320 - accuracy: 0.9523 - val_loss: 0.3973 - val_accuracy: 0.9158\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92094\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1196 - accuracy: 0.9536 - val_loss: 0.4392 - val_accuracy: 0.9145\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2d9f0f92eb8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model1.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "saved_model_1 = load_model('best_model_2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  5      378        99        0                   0   \n",
      "STANDING                 0       67       464        0                   0   \n",
      "WALKING                  0        0         0      467                  15   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 412   \n",
      "WALKING_UPSTAIRS         0        0         0       13                   2   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            9  \n",
      "STANDING                           1  \n",
      "WALKING                           14  \n",
      "WALKING_DOWNSTAIRS                 7  \n",
      "WALKING_UPSTAIRS                 456  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, saved_model_1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 14s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27421482619152027, 0.9209365248680115]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = saved_model_1.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 128, 128)          70656     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 120,454\n",
      "Trainable params: 120,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model1 = Sequential()\n",
    "# Configuring the parameters\n",
    "model1.add(LSTM(128, return_sequences=True, input_shape=(128,9)))\n",
    "# Adding a dropout layer\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "model1.add(LSTM(64))\n",
    "# Adding a dropout layer\n",
    "model1.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model1.add(Dense(n_classes, activation='sigmoid'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks.callbacks import EarlyStopping\n",
    "from keras.callbacks.callbacks import ModelCheckpoint\n",
    "checkpoint_1 = ModelCheckpoint(\"best_model_3.1\", monitor=\"val_accuracy\",mode=\"max\",save_best_only = True, verbose=1) \n",
    "\n",
    "\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=5)\n",
    "callbacks = [checkpoint_1,early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 1.0782 - accuracy: 0.5335 - val_loss: 0.8807 - val_accuracy: 0.6040\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60400, saving model to best_model_3.1\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.7853 - accuracy: 0.6530 - val_loss: 0.7115 - val_accuracy: 0.7095\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.60400 to 0.70954, saving model to best_model_3.1\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.6406 - accuracy: 0.7206 - val_loss: 0.5805 - val_accuracy: 0.7523\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.70954 to 0.75229, saving model to best_model_3.1\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.4090 - accuracy: 0.8376 - val_loss: 0.4350 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.75229 to 0.88090, saving model to best_model_3.1\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.2320 - accuracy: 0.9242 - val_loss: 0.4313 - val_accuracy: 0.8755\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.88090\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1961 - accuracy: 0.9297 - val_loss: 0.3692 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.88090\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1701 - accuracy: 0.9396 - val_loss: 0.6784 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.88090\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1557 - accuracy: 0.9436 - val_loss: 0.3458 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.88090 to 0.90702, saving model to best_model_3.1\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1580 - accuracy: 0.9440 - val_loss: 0.2560 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.90702\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1599 - accuracy: 0.9436 - val_loss: 0.3452 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.90702\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1501 - accuracy: 0.9396 - val_loss: 0.2587 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.90702 to 0.91483, saving model to best_model_3.1\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1288 - accuracy: 0.9459 - val_loss: 0.4389 - val_accuracy: 0.9030\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91483\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1542 - accuracy: 0.9419 - val_loss: 0.3629 - val_accuracy: 0.9063\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91483\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1491 - accuracy: 0.9450 - val_loss: 0.3270 - val_accuracy: 0.9152\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.91483 to 0.91517, saving model to best_model_3.1\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1336 - accuracy: 0.9501 - val_loss: 0.3026 - val_accuracy: 0.9264\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91517 to 0.92637, saving model to best_model_3.1\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1317 - accuracy: 0.9491 - val_loss: 0.3852 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92637\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1296 - accuracy: 0.9505 - val_loss: 0.2898 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92637\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1260 - accuracy: 0.9528 - val_loss: 0.3559 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92637\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1273 - accuracy: 0.9540 - val_loss: 0.3287 - val_accuracy: 0.8985\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92637\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1333 - accuracy: 0.9514 - val_loss: 0.3077 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2da15718fd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model1.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "saved_model_2 = load_model('best_model_3.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                 24      387        77        0                   0   \n",
      "STANDING                 0       61       470        0                   0   \n",
      "WALKING                  0        0         0      454                  40   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 419   \n",
      "WALKING_UPSTAIRS         0        1         0        1                   6   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            3  \n",
      "STANDING                           1  \n",
      "WALKING                            2  \n",
      "WALKING_DOWNSTAIRS                 1  \n",
      "WALKING_UPSTAIRS                 463  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, saved_model_2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 14s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3025784575979611, 0.9263657927513123]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = saved_model_2.evaluate(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------+------------------+---------+---------------+-----------+\n",
      "| S.NO | No. of Hidden Layers | No.of lstm units | Dropout | TEST ACCURACY | TEST LOSS |\n",
      "+------+----------------------+------------------+---------+---------------+-----------+\n",
      "|  1   |          1           |        32        |   0.25  |     0.8948    |   0.3549  |\n",
      "|  2   |          2           |        32        |   0.75  |     0.6244    |   0.7772  |\n",
      "|  3   |          2           |        20        |   0.5   |     0.9040    |   0.4683  |\n",
      "|  4   |          2           |        24        |   0.5   |     0.9016    |   0.3812  |\n",
      "|  5   |          2           |        28        |   0.5   |     0.7234    |   0.7294  |\n",
      "|  6   |          2           |        28        |   0.75  |     0.5205    |   0.8599  |\n",
      "|  7   |          2           |        28        |   0.25  |     0.9074    |   0.4082  |\n",
      "+------+----------------------+------------------+---------+---------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = ['S.NO',\"No. of Hidden Layers\", \"No.of lstm units\", \"Dropout\", \"TEST ACCURACY\",'TEST LOSS']\n",
    "x.add_row([\"1\",\"1\",'32','0.25','0.8948','0.3549'])\n",
    "x.add_row([\"2\",\"2\",'32','0.75','0.6244','0.7772'])\n",
    "x.add_row([\"3\",\"2\",'20','0.5','0.9040','0.4683'])\n",
    "x.add_row([\"4\",\"2\",'24','0.5','0.9016','0.3812'])\n",
    "x.add_row([\"5\",\"2\",'28','0.5','0.7234','0.7294'])\n",
    "x.add_row([\"6\",\"2\",'28','0.75','0.5205','0.8599'])\n",
    "x.add_row([\"7\",\"2\",'28','0.25','0.9074','0.4082'])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1 hidden layer with 128 lstm units  and dropout rate of 0.25 we got test accuracy of 93.45% and test loss of 0.2467.\n",
    "With 2 hidden layers with 128 and 64 lstm units and dropout rates of 0.2 and 0.5 respectively we got test accuracy of 92.63% and\n",
    "test loss of 0.3025. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
